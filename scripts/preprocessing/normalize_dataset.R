################################################################################
# Brain clock: log2 transforms and quantile-normalizes the data, offering      #
# the option of including a dataframe of train test assignments (generated by  #
# train_test_split.R) to apply quantile normalization first in the train set,  #
# and then map the resulting distribution to the rest of the samples,          #
# preventing data leakage.                                                     #
################################################################################
if (!require("preprocessCore", quietly = T)){
        BiocManager::install("preprocessCore", configure.args=c(preprocessCore = "--disable-threading"),
                             update = F)
}
if (!require("devtools",quietly = T)){
    install.packages("devtools",
                     repos = 'http://cran.us.r-project.org')
}
if(!require("plotUtils", quietly = T)){
        devtools::install_github('guisantagui/plotUtils', upgrade = "never")
}
library(plotUtils)
library(preprocessCore)
library(argparser)

# Terminal argument parser
################################################################################
parser <- arg_parser("Log2-transform and quantile-normalize the data, optionally being able to provide a train_test dataframe so only training set is used for determining the distribution.")

parser <- add_argument(parser = parser,
                       arg = "input",
                       help = "Counts matrix.",
                       flag = F)

parser <- add_argument(parser = parser,
                       arg = "--train_test",
                       help = "A file of train/test assignments. Generated with train_test_split.R",
                       flag = F,
                       default = NULL)

#parser <- add_argument(parser = parser,
#                       arg = "--outDir",
#                       help = "The output directory.",
#                       flag = F)

parsed <- parse_args(parser)

# Directory stuff
################################################################################
counts_f <- "../../results/parsed/merged/merged_counts.csv"
train_test_f <- "../../results/parsed/merged/train_test.csv"
#train_test_f <- NULL

counts_f <- parsed$input
train_test_f <- parsed$train_test
#outDir <- parsed$outDir

#create_dir_if_not(outDir)
#out_name <- gsub(".csv", "_log2_qnorm.csv", basename(counts_f))
out_name <- gsub(".csv", "_log2_qnorm.csv", counts_f)
#out_name <- sprintf("%s%s", outDir, out_name)

# Load data
################################################################################
counts <- read_table_fast(counts_f, row.names = 1)


# Transform
################################################################################
counts <- t(counts)
counts_log2 <- log2(counts + 1)

# Normalize
################################################################################

if (!is.na(train_test_f) && file.exists(train_test_f)){
        print("Performing quantile-normalization on the train set and applying it to the rest of the samples...")
        train_test <- read_table_fast(train_test_f, row.names = 1)
        # Split in train and test
        trainSamps <- make.names(train_test$specimenID[train_test$train_test_split == "train"])
        restSamps <- colnames(counts)[!colnames(counts) %in% trainSamps]
        counts_log2_train <- counts_log2[, colnames(counts_log2) %in% trainSamps]
        counts_log2_rest <- counts_log2[, colnames(counts_log2) %in% restSamps]

        # Normalize train
        counts_log2_train_qnorm <- normalize.quantiles(counts_log2_train)
        dimnames(counts_log2_train_qnorm) <- dimnames(counts_log2_train)

        # Extract the distribution
        train_target <- normalize.quantiles.determine.target(counts_log2_train_qnorm)

        # Apply the distribution to test
        counts_log2_rest_qnorm <- normalize.quantiles.use.target(counts_log2_rest,
                                                                 train_target)
        dimnames(counts_log2_rest_qnorm) <- dimnames(counts_log2_rest)

        # Merge
        counts_log2_qNorm <- cbind(counts_log2_train_qnorm,
                                   counts_log2_rest_qnorm)

        counts_log2_qNorm <- t(counts_log2_qNorm)

        # Reorder rows to match the input
        counts_log2_qNorm <- counts_log2_qNorm[match(make.names(colnames(counts)),
                                                     rownames(counts_log2_qNorm)), ]
}else{
        print("Performing quantile-normalization on the entire dataset...")
        counts_log2_qNorm <- normalize.quantiles(counts_log2)
        dimnames(counts_log2_qNorm) <- dimnames(counts_log2)
        train_target <- normalize.quantiles.determine.target(counts_log2_qNorm)
        counts_log2_qNorm <- t(counts_log2_qNorm)
}


# Save outputs
################################################################################

# Normalized matrix
write_table_fast(counts_log2_qNorm, out_name)
print(sprintf("%s saved at %s", basename(out_name), dirname(out_name)))

# Train target vector
train_target_f <- sprintf("%s/train_target.rds", dirname(counts_f))
saveRDS(train_target, train_target_f)